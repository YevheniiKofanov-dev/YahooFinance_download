{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc198079-3468-4bc2-8092-e6775a0ad923",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "from pyspark.sql.functions import lit, col\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eb00444c-d5ba-4fc0-9cc4-f4282702427f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Get the parameter's value\n",
    "ticker_symbol = dbutils.widgets.get(\"ticker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "450af01f-2f2e-4d17-8fa3-7cb460acdc05",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Update the status of the process to failed if it is still running\n",
    "query = f\"\"\"\n",
    "UPDATE yahoo_finance.processrunlogs.processrunlog\n",
    "SET status = 'Failed'\n",
    "WHERE ticker = '{ticker_symbol}'\n",
    "  AND processname = 'load_stock_data'\n",
    "  AND status = 'Running'\n",
    "  \"\"\"\n",
    "spark.sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0383df44-8641-4099-b905-1948544f5346",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "current_datetime = datetime.now()\n",
    "current_datetime_str = current_datetime.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "spark.sql(\n",
    "    f\"\"\"\n",
    "    INSERT INTO yahoo_finance.processrunlogs.processrunlog \n",
    "    (ticker, processname, last_loaded_date, startdate, status) \n",
    "    VALUES ('{ticker_symbol}', 'load_stock_data', null, '{current_datetime_str}', 'Running')\n",
    "    \"\"\"\n",
    ")\n",
    "end_date = current_datetime.date() + timedelta(days=1)\n",
    "end_date = end_date.strftime('%Y-%m-%d')\n",
    "\n",
    "last_loaded_datetime = spark.sql(\n",
    "    f\"\"\"\n",
    "    SELECT NVL(MAX(last_loaded_date), CAST('2025-01-01' AS timestamp)) \n",
    "    FROM yahoo_finance.processrunlogs.processrunlog \n",
    "    WHERE ticker = '{ticker_symbol}' \n",
    "    AND processname = 'load_stock_data' \n",
    "    AND status = 'Completed'\n",
    "    AND last_loaded_date IS NOT NULL\n",
    "    \"\"\"\n",
    ").collect()[0][0]\n",
    "\n",
    "# If last_loaded_datetime is a string, parse it to a date\n",
    "if isinstance(last_loaded_datetime, str):\n",
    "    start_date = datetime.strptime(last_loaded_datetime, '%Y-%m-%d').strftime('%Y-%m-%d')\n",
    "else:\n",
    "    start_date = last_loaded_datetime.strftime('%Y-%m-%d')\n",
    "# Download data for the given ticker symbol from Yahoo Finance\n",
    "bronze_pd_data = yf.download(\n",
    "    ticker_symbol,\n",
    "    start=start_date,\n",
    "    end=end_date,\n",
    "    interval=\"60m\",\n",
    "    auto_adjust=True\n",
    ")\n",
    "# Reset index of the Pandas dataframe to make Datetime ordinal column\n",
    "bronze_pd_data = bronze_pd_data.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a12861ef-982d-4ee8-a486-1035461c686a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Convert loaded data to Spark DataFrame\n",
    "bronze_spark_data = spark.createDataFrame(bronze_pd_data)\n",
    "# Add ticker column and rename columns to remove ticker name from column names\n",
    "bronze_spark_data = bronze_spark_data.withColumn(\"ticker\", lit(ticker_symbol)) \\\n",
    "             .withColumn(\"Datetime\", col(\"('Datetime', '')\").cast(\"string\")) \\\n",
    "             .withColumn(\"Close\", col(f\"('Close', '{ticker_symbol}')\").cast(\"string\")) \\\n",
    "             .withColumn(\"High\", col(f\"('High', '{ticker_symbol}')\").cast(\"string\")) \\\n",
    "             .withColumn(\"Low\", col(f\"('Low', '{ticker_symbol}')\").cast(\"string\")) \\\n",
    "             .withColumn(\"Open\", col(f\"('Open', '{ticker_symbol}')\").cast(\"string\")) \\\n",
    "             .withColumn(\"Volume\", col(f\"('Volume', '{ticker_symbol}')\").cast(\"string\")) \\\n",
    "             .drop(f\"('Close', '{ticker_symbol}')\", f\"('High', '{ticker_symbol}')\", f\"('Low', '{ticker_symbol}')\", f\"('Open', '{ticker_symbol}')\", f\"('Volume', '{ticker_symbol}')\", \"('Datetime', '')\")\n",
    "# Keep only the rows with Datetime greater than the last_loaded_date to avoid duplicates\n",
    "bronze_spark_data_filtered = bronze_spark_data.filter(col(\"Datetime\").cast(\"timestamp\") > last_loaded_datetime)\n",
    "# Save the filtered data to the bronze layer\n",
    "bronze_spark_data_filtered.write.format(\"delta\").mode(\"append\").save(\"abfss://bronze@yahoofinancestorage.dfs.core.windows.net/finance_bronze\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f130d814-8e3c-4154-b589-985e82f5a268",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Audit the process\n",
    "from pyspark.sql.functions import max as spark_max\n",
    "from datetime import datetime\n",
    "\n",
    "current_datetime = datetime.now()\n",
    "current_datetime_str = current_datetime.strftime('%Y-%m-%d %H:%M:%S')\n",
    "# Find the latest loaded datetime in the newly loaded data\n",
    "last_loaded_date_row = bronze_spark_data_filtered.agg(\n",
    "    spark_max(\"Datetime\").alias(\"max_datetime\")\n",
    ").collect()[0]\n",
    "\n",
    "max_datetime_val = last_loaded_date_row[\"max_datetime\"]\n",
    "\n",
    "if max_datetime_val is not None:\n",
    "    # If max_datetime_val is a datetime object, convert to string first\n",
    "    if isinstance(max_datetime_val, datetime):\n",
    "        last_loaded_date = max_datetime_val\n",
    "    else:\n",
    "        last_loaded_date = datetime.strptime(str(max_datetime_val), '%Y-%m-%d %H:%M:%S')\n",
    "else:\n",
    "    # Handle the case where there is no data\n",
    "    last_loaded_date = None\n",
    "# Get string representation of the latest loaded datetime to use in SQL scripts\n",
    "if last_loaded_date is not None:\n",
    "    last_loaded_date_str = last_loaded_date.strftime('%Y-%m-%d %H:%M:%S')\n",
    "else:\n",
    "    last_loaded_date_str = None \n",
    "\n",
    "if last_loaded_date_str is not None:\n",
    "    # Update the last_loaded_date because there is new data\n",
    "    spark.sql(\n",
    "        f\"\"\"\n",
    "        UPDATE yahoo_finance.processrunlogs.processrunlog\n",
    "        SET last_loaded_date = '{last_loaded_date_str}',\n",
    "            enddate = '{current_datetime_str}',\n",
    "            status = 'Completed'\n",
    "        WHERE id = (\n",
    "            SELECT MAX(id) FROM yahoo_finance.processrunlogs.processrunlog\n",
    "            WHERE ticker = '{ticker_symbol}'\n",
    "            AND processname = 'load_stock_data'\n",
    "            AND status = 'Running'\n",
    "        )\n",
    "        \"\"\"\n",
    "    )\n",
    "else:\n",
    "     # Do not update the last_loaded_date because there is no new data\n",
    "     spark.sql(\n",
    "        f\"\"\"\n",
    "        UPDATE yahoo_finance.processrunlogs.processrunlog\n",
    "        SET enddate = '{current_datetime_str}',\n",
    "            status = 'Completed'\n",
    "        WHERE id = (\n",
    "            SELECT MAX(id) FROM yahoo_finance.processrunlogs.processrunlog\n",
    "            WHERE ticker = '{ticker_symbol}'\n",
    "            AND processname = 'load_stock_data'\n",
    "            AND status = 'Running'\n",
    "        )\n",
    "        \"\"\"\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8270737159568307,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "YahooFinance_ingest_bronze",
   "widgets": {
    "ticker": {
     "currentValue": "MSFT",
     "nuid": "421ae607-12cd-4193-bcb4-c5a66291fba7",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": "",
      "name": "ticker",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": "",
      "name": "ticker",
      "options": {
       "widgetType": "text",
       "autoCreated": false,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
